{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnoXYOlfjSvb"
   },
   "source": [
    "# Convolutional neural networks 101\n",
    "\n",
    "Convolution neural networks are one of the most successful types of neural networks for image recognition and an integral part of reigniting the interest in neural networks. They are able to extract structural relations in the data, such as spatial in images or temporal in time series.\n",
    "\n",
    "In this lab, we will experiment with inserting 2D-convolution layers in the fully connected neural networks introduced previously. We will also try to visualize the learned convolution filters and try to understand what kind of features they learn to recognize.\n",
    "\n",
    "If you have not watched Jason Yosinski's [video on visualizing convolutional networks](https://www.youtube.com/watch?v=AgkfIQ4IGaM), you definitely should do so now. If you are unfamiliar with the convolution operation, [Vincent Dumoulin](https://github.com/vdumoulin/conv_arithmetic) has a nice visualization of different convolution variants. For a more in-depth tutorial, please see [cs231n.github.io/convolutional-networks](http://cs231n.github.io/convolutional-networks) or [neuralnetworksanddeeplearning.com/chap6.html](http://neuralnetworksanddeeplearning.com/chap6.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lMa9SSfjSvl"
   },
   "source": [
    "## Reminder: what are convolutional networks?\n",
    "\n",
    "Standard ConvNets are, in many respects, very similar to the dense feedforward networks we saw previously:\n",
    " * The network is still organized into layers.\n",
    " * Each layer is parameterized by weights and biases.\n",
    " * Each layer has an element-wise non-linear transformation (activation function).\n",
    " * There are no cycles in the connections (more on this in later labs).\n",
    "\n",
    "*So what is the difference?*\n",
    "The networks we saw previously are called *dense* because each unit receives input from all the units in the previous layer. This is not the case for ConvNets. In ConvNets each unit is only connected to a small subset of the input units. This is called the *receptive field* of the unit.\n",
    "\n",
    "#### Example\n",
    "The input (green matrix) is a tensor of size `1x5x5`, i.e., it has one \"channel\" (like a grayscale image), and the feature map has size `5x5`. Let us define a `1x3x3` kernel (yellow submatrix). The kernel weights are indicated in red at the bottom right of each element. The computation can be thought of as an elementwise multiplication followed by a sum. Here we use a *stride* of 1, as shown in this animation:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/master/4_Convolutional/images/convolutions.gif\" style=\"width: 400px;\"/>\n",
    "\n",
    "GIF courtesy of [Stanford](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)\n",
    "\n",
    "After having convolved the image, we perform an elementwise non-linear transformation on the *convolved features*.\n",
    "In this example, the input is a 2D *feature map* with depth 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOLUjfUZjSvn"
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "### Assignment 1.1: Manual calculations\n",
    "\n",
    "Perform the following computation, and write the result below.\n",
    "\n",
    "![](https://raw.githubusercontent.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/master/4_Convolutional/images/conv_exe.png)\n",
    "\n",
    "1. Manually convolve the input, and compute the convolved features. No padding and stride of 1.\n",
    " * **Answer:**\n",
    "2. Perform `2x2` max pooling on the convolved features. Stride of 2.\n",
    " * **Answer:**\n",
    "\n",
    "### Assignment 1.2: Output dimensionality\n",
    "\n",
    "Given the following 3D tensor input `(channel, height, width)`, a given amount (`channels_out`) of filters `(channels_in, filter_height, filter_width)`, stride `(height, width)` and padding `(height, width)`, calculate the output dimensionality if it is valid.\n",
    "\n",
    "1. input tensor with dimensionality (1, 28, 28) and 16 filters of size (1, 5, 5) with stride (1, 1) and padding (0, 0)\n",
    " * **Answer:** \n",
    "2. input tensor with dimensionality (2, 32, 32) and 24 filters of size (2, 3, 3) with stride (1, 1) and padding (0, 0)\n",
    " * **Answer:** \n",
    "3. input tensor with dimensionality (10, 32, 32) and 3 filters of size (10, 2, 2) with stride (2, 2) and padding (0, 0)\n",
    " * **Answer:** \n",
    "4. input tensor with dimensionality (11, 8, 16) and 7 filters of size (11, 3, 3) with stride (2, 2) and padding (1, 1)\n",
    " * **Answer:** \n",
    "5. input tensor with dimensionality (128, 256, 256) and 112 filters of size (128, 3, 3) with stride (1, 1) and padding (1, 1)\n",
    " * **Answer:** \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTsZa_xhjSvp"
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3086,
     "status": "ok",
     "timestamp": 1662639635584,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "oFUsDSEtjSvq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpD2ZUGWjSvs"
   },
   "source": [
    "# Load MNIST data\n",
    "\n",
    "The code below downloads and loads the same MNIST dataset as before.\n",
    "Note however that the data has a different shape this time: `(num_samples, num_channels, height, width)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset_full = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Create subsets: 50,000 for training, 10,000 for validation/testing\n",
    "train_dataset = Subset(train_dataset_full, range(50000))\n",
    "validation_dataset = Subset(train_dataset_full, range(50000, 60000))\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = train_dataset.dataset.targets.unique().size(0)\n",
    "\n",
    "# Extract a batch from each dataset and print its shape\n",
    "x_train, targets_train = next(iter(DataLoader(train_dataset, batch_size=64)))\n",
    "x_valid, targets_valid = next(iter(DataLoader(validation_dataset, batch_size=64)))\n",
    "x_test, targets_test = next(iter(DataLoader(test_dataset, batch_size=64)))\n",
    "\n",
    "print(\"Information on dataset\")\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of targets_train:\", targets_train.shape)\n",
    "print(\"Shape of x_valid:\", x_valid.shape)\n",
    "print(\"Shape of targets_valid:\", targets_valid.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of targets_test:\", targets_test.shape)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 100 images from the training set\n",
    "images, labels = next(iter(DataLoader(train_dataset, batch_size=100, shuffle=True)))\n",
    "\n",
    "# Plot a few MNIST examples\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.imshow(make_grid(images, nrow=10).permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcq0TsjbjSv1"
   },
   "source": [
    "# Define a simple feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1662639671015,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "_Cb9FsjajSv2",
    "outputId": "7691e76d-3420-436f-e0c6-9072cdf925f4"
   },
   "outputs": [],
   "source": [
    "channels, height, width = x_train.shape[1:]\n",
    "n_features = channels * height * width\n",
    "\n",
    "\n",
    "class PrintSize(nn.Module):\n",
    "    \"\"\"Utility module to print current shape of a Tensor in Sequential, only at the first forward pass.\"\"\"\n",
    "    \n",
    "    first = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.first:\n",
    "            print(f\"Size: {x.size()}\")\n",
    "            self.first = False\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        activation_fn = nn.ReLU\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),  # from (1, channels, height, width) to (1, channels * height * width)\n",
    "            nn.Linear(n_features, 128),\n",
    "            activation_fn(),\n",
    "            nn.Linear(128, 128),\n",
    "            activation_fn(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1662639684841,
     "user": {
      "displayName": "Ole Winther",
      "userId": "12097569893493878263"
     },
     "user_tz": -120
    },
    "id": "GPIgjOTFjSv6",
    "outputId": "7401463e-3427-4a1a-ec03-620dc002d312"
   },
   "outputs": [],
   "source": [
    "# Test the forward pass with dummy data\n",
    "out = model(torch.randn(2, 1, 28, 28))\n",
    "print(\"Output shape:\", out.size())\n",
    "print(f\"Output logits:\\n{out.detach().numpy()}\")\n",
    "print(f\"Output probabilities:\\n{out.softmax(1).detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5kIR7JTjSv7"
   },
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eBO7B36jSv7"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "validation_every_steps = 500\n",
    "\n",
    "# Make data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "        \n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_accuracies_batches = []\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        \n",
    "        # Forward pass.\n",
    "        output = model(inputs)\n",
    "        \n",
    "        # Compute loss.\n",
    "        loss = loss_fn(output, targets)\n",
    "        \n",
    "        # Clean up gradients from the model.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients based on the loss from the current batch (backpropagation).\n",
    "        loss.backward()\n",
    "        \n",
    "        # Take one optimizer step using the gradients computed in the previous step.\n",
    "        optimizer.step()\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        # Compute accuracy.\n",
    "        predictions = output.max(1)[1]\n",
    "        train_accuracies_batches.append(accuracy_score(targets, predictions))\n",
    "        \n",
    "        if step % validation_every_steps == 0:\n",
    "            \n",
    "            # Append average training accuracy to list.\n",
    "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
    "            \n",
    "            train_accuracies_batches = []\n",
    "        \n",
    "            # Compute accuracies on validation set.\n",
    "            validation_accuracies_batches = []\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for inputs, targets in validation_loader:\n",
    "                    output = model(inputs)\n",
    "                    loss = loss_fn(output, targets)\n",
    "\n",
    "                    predictions = output.max(1)[1]\n",
    "\n",
    "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "                    validation_accuracies_batches.append(accuracy_score(targets, predictions) * len(inputs))\n",
    "\n",
    "                model.train()\n",
    "                \n",
    "            # Append average validation accuracy to list.\n",
    "            validation_accuracies.append(np.sum(validation_accuracies_batches) / len(validation_dataset))\n",
    "     \n",
    "            print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
    "            print(f\"             validation accuracy: {validation_accuracies[-1]}\")\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giiAmxpYjSv-"
   },
   "outputs": [],
   "source": [
    "steps = (np.arange(len(train_accuracies), dtype=int) + 1) * validation_every_steps\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(steps, train_accuracies, label='train')\n",
    "plt.plot(steps, validation_accuracies, label='validation')\n",
    "plt.xlabel('Training steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Train and validation accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_accuracies = []\n",
    "    for inputs, targets in test_loader:\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        predictions = output.max(1)[1]\n",
    "\n",
    "        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=True).\n",
    "        test_accuracies.append(accuracy_score(targets, predictions) * len(inputs))\n",
    "\n",
    "    test_accuracy = np.sum(test_accuracies) / len(test_dataset)\n",
    "    print(f\"Validation accuracy: {validation_accuracies[-1]:.3f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "    \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0l4hf_-ijSv-"
   },
   "source": [
    "### Assignment 2\n",
    "\n",
    "1. Note the performance of the standard feedforward neural network. Add a [2D convolution layer](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) before the first layer. Insert the utility module `PrintSize` to check the size of the tensor at any point in `Sequential`, and notice that the size of the image reduces after the convolution. This can cause loss of information, and can be avoided by using adequate padding in the convolutional layer.\n",
    "  Does adding a convolutional layer increase the generalization performance of the network (try num_filters=32 and filter_size=5 as a starting point)?\n",
    "  \n",
    "2. Can the performance be increases even further by stacking more convolution layers?\n",
    "\n",
    "3. We now have a deeper network than the initial simple feedforward network. What happens if we replace all convolutional layers with linear layers? Is this deep feedforward network performing as well as the convolutional one?\n",
    " \n",
    "4. Max-pooling is a technique for decreasing the spatial resolution of an image while retaining the important features. Effectively this gives a local translational invariance and reduces the computation by a factor of four. In the classification algorithm which is usually desirable. You can either: \n",
    " \n",
    "   - add a maxpool layer (see the PyTorch docs, and try with kernel_size=2 and stride=2) after the convolution layer, or\n",
    "   - add stride=2 to the arguments of the convolution layer directly.\n",
    "     \n",
    "  Verify that this decreases the spatial dimension of the image (insert a `PrintSize` module in the `Sequential`). Does this increase the performance of the network? Note that, to increase performance, you may need to stack multiple layers, increase the number of filters, or tune the learning rate.\n",
    "\n",
    "5. Dropout is a very useful technique for preventing overfitting. Try to add a DropoutLayer after some of the convolution layers. You may observe a higher validation accuracy but lower train accuracy. Can you explain why this might be the case?\n",
    " \n",
    "6. Batch normalization may help convergence in larger networks as well as generalization performance. Try to insert batch normalization layers into the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nxnfgk0JjSwA"
   },
   "source": [
    "Again, if you didn't already, you really should [watch this video](https://www.youtube.com/watch?v=AgkfIQ4IGaM)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
