{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced by https://github.com/pytorch/tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory RNN\n",
    "\n",
    "This notebook\n",
    "* Introduces the LSTM\n",
    "* Combines what we have seen in the previous two notebooks\n",
    "* Use an LSTM to perform sentiment analysis on SST\n",
    "__\n",
    "\n",
    "\n",
    "\n",
    "## Why does\n",
    "The vanilla RNN has issues with vanishing gradients which give challenges in saving memory over longer sequences.\n",
    "\n",
    "To battle these issues the gated hidden units were create.\n",
    "We have Long Short-Term Memory (LSTM) (see [Christopher Olah's walk through](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)) and Gated Recurrent Unit (GRU) which have shown increased performance in saving and reusing memory in later timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm](../static_files/lstm_cell.png)\n",
    "source: https://arxiv.org/abs/1412.7828\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The LSTM contains three gates, input, forget, output gates and a memory cell.\n",
    "The output of the LSTM unit is computed with the following functions, where $\\sigma = \\mathrm{softmax}$.\n",
    "We have input gate $i$, forget gate $f$, and output gate $o$ defines as\n",
    "\n",
    "- $i = \\sigma ( U^i x_t + W^i h_{t-1})$\n",
    "\n",
    "- $f = \\sigma ( U^f x_t + W^f h_{t-1})$\n",
    "\n",
    "- $o = \\sigma ( U^o x_t + W^o h_{t-1})$\n",
    "\n",
    "where $U^i, U^f, U^o$ are weight matrices applied to $x_t$ (input vector), and\n",
    "$W^i, W^f, W^o$ are weight matrices applied to $h_{t-1}$ (hidden state vector) for each respective gate.\n",
    "\n",
    "$h_{t-1}$, from the previous time step along with the current input $x_t$ are used to compute the a candidate $g$\n",
    "\n",
    "- $g = \\mathrm{tanh}( U^g x_t +  W^g h_{t-1})$\n",
    "\n",
    "The value of the cell's memory, $c_t$, is updated as\n",
    "\n",
    "- $c_t = c_{t-1} \\circ f + g \\circ i$\n",
    "\n",
    "where $c_{t-1}$ is the previous memory, and $\\circ$ refers to element-wise multiplication.\n",
    "\n",
    "The output, $h_t$, is computed as\n",
    "\n",
    "- $h_t = \\mathrm{tanh}(c_t) \\circ o$\n",
    "\n",
    "and it is used for both the timestep's output and the next timestep, whereas $c_t$ is exclusively sent to the next timestep.\n",
    "This makes $c_t$ a memory feature, and is not used directly to compute the output of the timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford sentiment treebank\n",
    "\n",
    "We will continue with the SST.\n",
    "See previous notebook for more information.\n",
    "\n",
    "The code below loads the data, similar to what we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, RNN, LSTM\n",
    "from torch.nn.functional import softmax, relu\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# we'll use the bokeh library to create beautiful plots\n",
    "# *_notebook functions are needed for correct use in jupyter\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume that all fields are sequential, i.e. there will be a sequence of data\n",
    "# however, the label field will not contain any sequence\n",
    "TEXT = data.Field(sequential=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "\n",
    "# create SST dataset splits\n",
    "# note, we remove samples with neutral labels\n",
    "train_set, validation_set, _ = datasets.SST.splits(TEXT,\n",
    "                                                   LABEL,\n",
    "                                                   fine_grained=False,\n",
    "                                                   train_subtrees=True,\n",
    "                                                   filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "# build the vocabularies\n",
    "# NOTE you should download the GloVe vocabulary, it is quite large..\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "TEXT.build_vocab(train_set, max_size=None, vectors=Vectors('wiki.simple.vec', url=url))\n",
    "\n",
    "# TEXT.build_vocab(train_set, max_size=None, vectors=[GloVe(name='840B', dim='300')])\n",
    "LABEL.build_vocab(train_set)\n",
    "# make iterator for splits\n",
    "# device gives a CUDA enabled device (-1 disables it)\n",
    "train_iter, val_iter, _ = data.BucketIterator.splits((train_set, validation_set, _),\n",
    "                                                     batch_size=128, \n",
    "                                                     device=0 if use_cuda else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n",
    "We now use an `RNN` to classify the sentences.\n",
    "(You will change this into an LSTM as an exercise).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of embeddings\n",
    "embedding_dim = TEXT.vocab.vectors.size()[1]\n",
    "num_embeddings = TEXT.vocab.vectors.size()[0]\n",
    "num_classes = len(LABEL.vocab.itos)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
    "\n",
    "        # use pretrained embeddings\n",
    "        self.embeddings.weight.data.copy_(TEXT.vocab.vectors)\n",
    "        self.embeddings.weight.detach_()\n",
    "        \n",
    "        self.rnn_1 = RNN(input_size=embedding_dim,\n",
    "                         hidden_size=100,\n",
    "                         num_layers=1,\n",
    "                         bidirectional=False)\n",
    "        self.l_out = Linear(in_features=200,\n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        # get embeddings\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        # rnn returns output and last hidden state\n",
    "        x, hn = self.rnn_1(x)\n",
    "        \n",
    "        # get a fixed sized hidden representation of the entire sequence\n",
    "        out['hidden'] = x = torch.cat((torch.mean(x, dim=0), torch.max(x, dim=0)[0]), dim=1)\n",
    "        \n",
    "        # classify\n",
    "        out['out'] = softmax(self.l_out(x), dim=1)\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we don't want to change the embedding.\n",
    "We therefore need to filter it out from the parameters that we pass to the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which params require grad\n",
    "{p[0]: p[1].requires_grad for p in net.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# we filter the model's parameters such that we can remove the embedding layer, \n",
    "# which does not have requires_grad\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = torch.eq(torch.max(ys, 1)[1], ts)\n",
    "    # averaging the one-hot encoded vector\n",
    "    return torch.mean(correct_prediction.float())\n",
    "\n",
    "def construct_sentences(batch):\n",
    "    return [\" \".join([TEXT.vocab.itos[elm] \n",
    "                      for elm in get_numpy(batch.text[:,i])])\n",
    "            for i in range(batch.text.size()[1])]\n",
    "\n",
    "def get_labels(batch):\n",
    "    return [LABEL.vocab.itos[get_numpy(batch.label[i])] for i in range(len(batch.label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to project our hidden embeddings to a visualizable space\n",
    "tsne = TSNE(perplexity=10.0, learning_rate=5.0, n_iter=2000)\n",
    "\n",
    "# index for each label\n",
    "colormap = {1: 'DodgerBlue', 2: 'FireBrick'}\n",
    "# create a tmp source to be updated later\n",
    "validation_set_size = len(validation_set)\n",
    "source = ColumnDataSource(data={'x': np.random.randn(validation_set_size),\n",
    "                                'y': np.random.randn(validation_set_size),\n",
    "                                'colors': ['green']*validation_set_size,\n",
    "                                'sentences': [\"tmp\"]*validation_set_size,\n",
    "                                'labels': [\"unk\"]*validation_set_size})\n",
    "# instance to define hover logic in plot\n",
    "hover = HoverTool(tooltips=[(\"Sentence\", \"@sentences\"), (\"Label\", \"@labels\")])\n",
    "\n",
    "# set up the bokeh figure for later visualizations\n",
    "p = figure(tools=[hover])\n",
    "p.circle(x='x', y='y', fill_color='colors', size=5, line_color=None, source=source)\n",
    "\n",
    "def update_plot(meta, layer, handle):\n",
    "    \"\"\" Update existing plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    meta: dict\n",
    "    layer: str\n",
    "    \"\"\"\n",
    "    tsne_acts = tsne.fit_transform(meta[layer])\n",
    "    source.data['x'] = tsne_acts[:,0]\n",
    "    source.data['y'] = tsne_acts[:,1]\n",
    "    source.data['colors'] = [colormap[l] for l in meta['label_idx']]\n",
    "    \n",
    "    source.data['sentences'] = meta['sentences']\n",
    "    source.data['labels'] = meta['labels']\n",
    "    \n",
    "    # this updates the given plot\n",
    "    push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTM Model\n",
    "\n",
    "**Warning** this might take a while.\n",
    "Go get a cop of coffe, and enjoy the visualizations.\n",
    "\n",
    "Notice that each data point in the plot corresponds to an entire sentence in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 25000\n",
    "eval_every = 1000\n",
    "log_every = 500\n",
    "tsne_every = eval_every * 5\n",
    "\n",
    "# will be updated while iterating\n",
    "tsne_plot = show(p, notebook_handle=True)\n",
    "\n",
    "train_loss, train_accs = [], []\n",
    "\n",
    "net.train()\n",
    "for i, batch in enumerate(train_iter):\n",
    "    if i % eval_every == 0:\n",
    "        net.eval()\n",
    "        val_losses, val_accs, val_lengths = 0, 0, 0\n",
    "        val_meta = {'label_idx': [], 'sentences': [], 'labels': []}\n",
    "        for val_batch in val_iter:\n",
    "            output = net(val_batch.text)\n",
    "            # batches sizes might vary, which is why we cannot just mean the batch's loss\n",
    "            # we multiply the loss and accuracies with the batch's size,\n",
    "            # to later divide by the total size\n",
    "            val_losses += criterion(output['out'], val_batch.label) * val_batch.batch_size\n",
    "            val_accs += accuracy(output['out'], val_batch.label) * val_batch.batch_size\n",
    "            val_lengths += val_batch.batch_size\n",
    "            \n",
    "            for key, _val in output.items():\n",
    "                if key not in val_meta:\n",
    "                    val_meta[key] = []\n",
    "                val_meta[key].append(get_numpy(_val)) \n",
    "            val_meta['label_idx'].append(get_numpy(val_batch.label))\n",
    "            val_meta['sentences'].append(construct_sentences(val_batch))\n",
    "            val_meta['labels'].append(get_labels(val_batch))\n",
    "        \n",
    "        for key, _val in val_meta.items():\n",
    "            val_meta[key] = np.concatenate(_val)\n",
    "        \n",
    "        # divide by the total accumulated batch sizes\n",
    "        val_losses /= val_lengths\n",
    "        val_accs /= val_lengths\n",
    "        \n",
    "        print(\"### EVAL loss: {:.2f} accs: {:.2f}\".format(get_numpy(val_losses),\n",
    "                                                          get_numpy(val_accs)))\n",
    "        if i % tsne_every == 0:\n",
    "            update_plot(val_meta, 'hidden', tsne_plot)\n",
    "        \n",
    "        net.train()\n",
    "    \n",
    "    output = net(batch.text)\n",
    "    batch_loss = criterion(output['out'], batch.label)\n",
    "    \n",
    "    train_loss.append(get_numpy(batch_loss))\n",
    "    train_accs.append(get_numpy(accuracy(output['out'], batch.label)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % log_every == 0:        \n",
    "        print(\"train, it: {} loss: {:.2f} accs: {:.2f}\".format(i, \n",
    "                                                               np.mean(train_loss), \n",
    "                                                               np.mean(train_accs)))\n",
    "        # reset\n",
    "        train_loss, train_accs = [], []\n",
    "        \n",
    "    \n",
    "    if max_iter < i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above vanilla model should achieve below 80% accuracy in evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments\n",
    "\n",
    "## Assignment 1\n",
    "\n",
    "Upgrade the model such that it is equivalent to the model presented in [Johansen & Socher](https://arxiv.org/abs/1712.05483).\n",
    "See figure A3 for an illustration.\n",
    "\n",
    "- Note, batch and sequence dimensions are flipped\n",
    "- A *projection layer* is a fully connected layer, which does not necessarily have a non-linearity\n",
    "- Notice, that you also need to update the optimizer\n",
    "\n",
    "> **Goal** you should see evaluation acccuracy around 86%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional reading material and lab\n",
    "\n",
    "- follow [pytorch's seq2seq lab](http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) for a complete implementation of a seq2seq model\n",
    "\n",
    "also, you might want to read the following articles (which are also mentioned in the above lab):\n",
    "\n",
    "- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
    "- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "- [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
