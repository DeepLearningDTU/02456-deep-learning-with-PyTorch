{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "try:\n",
    "    from plotting import make_vae_plots\n",
    "except Exception as ex:\n",
    "    print(f\"If using Colab, you may need to upload `plotting.py`. \\\n",
    "          \\nIn the left pannel, click `Files > upload to session storage` and select the file `plotting.py` from your computer \\\n",
    "          \\n---------------------------------------------\")\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You should first read the introduction from the Notebook about Autoencoders (notebook 7.1).*\n",
    "\n",
    "As background material we recommend reading [Tutorial on Variational Autoencoder](http://arxiv.org/abs/1606.05908). For the implementation of the model you can read the article \"Auto-Encoding Variational Bayes\", Kingma & Welling, ICLR 2014: http://arxiv.org/pdf/1312.6114v10.pdf and \"Stochastic Backpropagation and Approximate Inference in Deep Generative Models\", Rezende et al, ICML 2014: http://arxiv.org/pdf/1401.4082v3.pdf.\n",
    "\n",
    "# Variational Autoencoders\n",
    "\n",
    "Probabilistic Machine Learning is fundamental in modern machine learning. While deep learning methods have been criticized for their lack of explainability, building machine learning models using probabilistic principles provides statistical guarantees. This is a key component for deploying machine learning to critical infrastructures (healthcare, manufacturing, finance, etc.). The Variational Autoencoder embodies probabilistic principles for principled unsupervised learning.\n",
    "\n",
    "## 1. Probabilistic Design:  Designing a Generative Process\n",
    "\n",
    "<img src=\"static/vae.png\" />\n",
    "\n",
    "In the notebook 7.1, the goal was to learn a set of features $\\mathbf{z} \\in \\mathcal{R}^M$ explaining the *observation* variable $\\mathbf{x} \\in \\mathcal{R}^{P}$. Learning was performed by autoencoding $\\mathbf{x}$ through an *information bottleneck*. In this setting however, the quality of the representation is greatly impacted by the choice of the dimension $M$ of the bottleneck.\n",
    "\n",
    "The unobserved variable — or *latent variable* — can be modelled using a probabilistic framework, this allows us to build the model in a principled way, and overcomes many of the limitations of the basic autoencoder (e.g. choice of the dimension of the bottleneck). $\\mathbf{z}$ is chosen to represent the generative factors of $\\mathbf{x}$, we define a generative process \n",
    "\n",
    "$$\\mathbf{z} \\sim p_{\\theta}(\\mathbf{z}), \\  \\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} | \\mathbf{z})$$ \n",
    "\n",
    "where the **prior** $p_{\\theta}(\\mathbf{z})$ is a chosen distribution (e.g. $\\mathcal{N}(0 , I)$) and the **observation model** $p_\\theta(\\mathbf{x} | \\mathbf{z})$ is a distribution depending on the variable $\\mathbf{z}$. Since we are interested in learning a model that explains well the data, we aim at maximizing the probability assigned to $\\mathbf{x}$. Therefore the optimal parameter $\\theta^\\star$ is given by\n",
    "\n",
    "$$\\theta^\\star := \\mathop{\\mathrm{argmax}}_\\theta p_\\theta (\\mathbf{x}) = \\int_\\mathbf{z} p_\\theta(\\mathbf{x}, \\mathbf{z}) d\\mathbf{z} = \\int_\\mathbf{z} p_\\theta(\\mathbf{x} | \\mathbf{z}) p_\\theta(\\mathbf{z}) d \\mathbf{z} \\ .$$\n",
    "\n",
    "## 2. Amortized Variational Inference: Estimatin the Likelihood \n",
    "\n",
    "### Intractability of the Likelihood\n",
    "\n",
    "In practice, $p_{\\theta}(\\mathbf{x})$ is **intractable**: marginalizing over $\\mathbf{z}$ is prohibitively expensive. A potential solution consists in using the *posterior distribution* which we can express using Bayes Rule:\n",
    "\n",
    "$$p_\\theta(\\mathbf{z} | \\mathbf{x}) =  \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z})}{p_{\\boldsymbol{\\theta}}(\\mathbf{x})} \\ . $$\n",
    "\n",
    "However $p_\\theta(\\mathbf{x} | \\mathbf{z})$ is also intractable as it requires evaluating $p_\\theta (\\mathbf{x} )$.\n",
    "\n",
    "### Approximate Posterior\n",
    "\n",
    "**Variational Inference** (VI) overcomes the intractability of the *true posterior* $p_\\theta(\\mathbf{z} | \\mathbf{x})$ by introducing an **approximate posterior**\n",
    "\n",
    "$$q_\\phi(\\mathbf{z} | \\mathbf{x}) \\approx p_\\theta(\\mathbf{z} | \\mathbf{x}) \\ . $$ \n",
    "\n",
    "$q_\\phi(\\cdot| \\mathbf{x})$ is chosen among a *variational family* $\\mathcal{Q}$. A common choice for $\\mathcal{Q}$ is the Gaussian family, although it is possible to use other families (Categorical, Poisson, etc.). In the case of the Gaussian family, a common choice is the isotropic Gaussian (diagonal covariance)\n",
    "\n",
    "$$q_\\phi(\\mathbf{z} | \\mathbf{x}) := \\mathcal{N}( \\mathbf{z}\\ |\\ \\mu_\\phi(\\mathbf{x}) , \\sigma_\\phi(\\mathbf{x}) I )$$\n",
    "\n",
    "parameterized by neural networks $\\mu_\\phi(\\mathbf{x}) $ and $ \\sigma_\\phi(\\mathbf{x})$. Because the inference model $\\{ \\mu_\\phi, \\sigma_\\phi \\}$ is shared among all datapoints $\\{\\mathbf{x}_i, \\mathbf{y}_i\\}_{i=1, \\dots, N}$, we say that we use **amortized** Variational Inference. Non-amortized Variational Inference would consider one model $\\{ \\mu_\\phi, \\sigma_\\phi \\}$ for each datapoint $\\mathbf{x}$.\n",
    "\n",
    "The introduction of the approximate posterior allows to express the likelihood $p_\\theta (\\mathbf{x})$ as an expectation over $q_\\phi(\\mathbf{z} | \\mathbf{x})$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p_\\theta (\\mathbf{x})  = \\int_\\mathbf{z} p_\\theta(\\mathbf{x} ,\\mathbf{z}) d \\mathbf{z}\n",
    "= \\int_\\mathbf{z} \\frac{q_\\phi(\\mathbf{z} | \\mathbf{x})}{q_\\phi(\\mathbf{z} | \\mathbf{x})} p_\\theta(\\mathbf{x}, \\mathbf{z}) d \\mathbf{z}\n",
    "= \\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[\n",
    "\\frac{p_\\theta(\\mathbf{x}, \\mathbf{z})}{q_\\phi(\\mathbf{z} | \\mathbf{x})}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "### Evidence Lower Bound (ELBO)\n",
    "\n",
    "Computing a Monte-Carlo estimate $\\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[ \\cdot \\right]$ of the ratio $\\frac{p_\\theta(\\mathbf{x}, \\mathbf{z})}{q_\\phi(\\mathbf{z} | \\mathbf{x})}$\n",
    "is computationally challenging due to its high variance and the numerically instability cause by the term $\\frac{1}{q_\\phi(\\mathbf{z} | \\mathbf{x})}$. Instead, we leverage well-behaved log-space computation thanks to [Jensen's Inequality](https://en.wikipedia.org/wiki/Jensen%27s_inequality), which gives the Evidence Lower Bound (ELBO) $\\mathcal{L} (\\mathbf{x})$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p_\\theta (\\mathbf{x}) & = \\log \\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[ \n",
    "\\frac{p_\\theta(\\mathbf{x}, \\mathbf{z})}{q_\\phi(\\mathbf{z} | \\mathbf{x})} \n",
    "\\right]  \\geq  \\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[ \n",
    "\\log \\frac{p_\\theta(\\mathbf{x}, \\mathbf{z})}{q_\\phi(\\mathbf{z} | \\mathbf{x})} \n",
    "\\right] =: \\mathcal{L} (\\mathbf{x})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Is it possible to express the ELBO using [a KL divergence](https://en.wikipedia.org/wiki/Kullback–Leibler_divergence), which measure how two distributions differ from each other: \n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x}) := \\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[ \n",
    "\\log p_\\theta(\\mathbf{x} | \\mathbf{z}) - \\log q_\\phi(\\mathbf{z} | \\mathbf{x}) + \\log p_\\theta(\\mathbf{z}) \n",
    "\\right] =\n",
    "\\overbrace{\n",
    "\\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[ \\log p_\\theta(\\mathbf{x} | \\mathbf{z})\\right]\n",
    "}^{\\text{(a) Reconstruction Error}}\n",
    "- \n",
    "\\overbrace{\n",
    "\\mathcal{D}_{\\operatorname{KL}}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x})\\ |\\ p(\\mathbf{z})\\right)\n",
    "}^{\\text{(b) Regularization}}\n",
    "$$\n",
    "\n",
    "Optimizing the ELBO results in a tradeoff between the terms (a) and (b). The term (a) mesaures the reconstruction quality while the term (b) enforces the posterior $q_\\phi(\\mathbf{z} | \\mathbf{x})$ to match the prior $p(\\mathbf{z})$. A stronger regularization (penalizing more the KL term b.), the more difficult it is to produce good reconstructions.\n",
    "\n",
    "\n",
    "## 3. Learning the Optimal Parameters: the Reparameterization Trick\n",
    "\n",
    "The ELBO is a lower bound to the log-likelihood, meaning that maximizing the ELBO results in maximizing the likelihood.\n",
    "Assuming that both the inference network $q_\\phi(\\mathbf{z} | \\mathbf{x})$ and\n",
    "the generative model $p_\\theta(\\mathbf{x} | \\mathbf{z})$ are implemented using network, we can apply backpropagation\n",
    "through all layers but not through the sampling operation $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$. In the next paragraph we will see how to optimize the parameters $\\theta$ and $\\phi$ w.r.t $\\mathcal{L}$.\n",
    "\n",
    "### Optimizing $\\theta$: Backropagation\n",
    "\n",
    "The ELBO is a lower bound to the marginal log-likelihood: $ \\mathcal{L} \\leq \\log p_\\theta (\\mathbf{x})$.\n",
    "Therefore we use stochastic gradient descent to minimize the negative ELBO. The gradient of the parameters $\\theta$ can be evaluated analytically\n",
    "using backpropagation (see the computational graph in the figure section *reparameterization trick*).\n",
    "\n",
    "###  Optimizing $\\phi$: Monte Carlo Gradient Estimation and the Reparameterization Trick\n",
    "\n",
    "**Estimating the gradient w.r.t. $\\phi$ is challenging** due to the sampling operation $\\mathbf{z} \\sim q_{\\phi}(\\mathbf{z} | \\mathbf{x})$\n",
    "that requires integrating over $q_\\phi(\\mathbf{z}|\\mathbf{x})$. Here is an extensive review of the existing methods for\n",
    "[Monte Carlo Gradient Estimation in Machine Learning](https://arxiv.org/pdf/1906.10652.pdf).\n",
    "\n",
    "#### Naïve approach: Reinforce\n",
    "\n",
    "The usual Monte Carlo Gradient estimator for this type of problem is the Reinforce — or the score-function — gradient estimator.\n",
    "In a simplified setting of a loss function (score) of the general form $f_{\\theta}(\\mathbf{z},  \\mathbf{x})$, the following identify holds: $$\\nabla_{\\boldsymbol{\\phi}} \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\mathbf{z} | \\mathbf{x})}[f_\\theta(\\mathbf{z}, \\mathbf{x})]=\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\mathbf{z} |  \\mathbf{x})}\\left[f_\\theta(\\mathbf{z},  \\mathbf{x}) \\nabla_{\\phi} \\log q_{\\boldsymbol{\\phi}}(\\mathbf{z} |  \\mathbf{x})\\right] \\text{  (Reinforce)}$$ . This gradient estimator suffers however from large variance, as a consequence learning will be inefficient.\n",
    "\n",
    "#### The Reparameterization Trick / Pathwise Derivatives\n",
    "\n",
    "<img src=\"static/reparameterization.png\" width=\"70%\" />\n",
    "\n",
    "The key component of the [the original Variational Autoencoder](https://arxiv.org/pdf/1312.6114.pdf) consists in using the Law of the Unconscious Statistician (LOTUS)\n",
    "to derive a **low-variance estimate of the gradient of $\\phi$**: this is the **Reparameterization Trick** (also known as pathwise derivatives). The trick consists in\n",
    "1. introducing a noise variable $\\epsilon$ with a fixed base distribution $p(\\epsilon)$\n",
    "2. introducing a deterministic and differentiable transformation $g_\\phi (\\epsilon, \\mathbf{x})$\n",
    "\n",
    "Such that $$\\mathbf{z} \\sim q_\\phi(\\mathbf{z}| \\mathbf{x}) \\text{ is equivalent to } \\mathbf{z} = g_\\phi(\\epsilon, \\mathbf{x}), \\epsilon \\sim p(\\epsilon) \\ .$$\n",
    "\n",
    "In this setting, a low-variance estimate of the gradient of the ELBO w.r.t $\\phi$ is given by:\n",
    "\n",
    "$$\\nabla_\\phi \\mathcal{L}(\\mathbf{x}) := \\nabla_\\phi \\mathbb{E}_{q_{\\phi}\\left(\\mathbf{z} \\mid \\mathbf{x}\\right)}[f_{\\theta, \\phi}(\\mathbf{z}, \\mathbf{x})]=\\mathbb{E}_{p(\\boldsymbol{\\epsilon})}\\left[ \\nabla_\\phi f_{\\theta, \\phi}\\left(\\tilde{\\mathbf{z}}, \\mathbf{x}\\right)\\right] \\text{  (Reparameterization)}$$\n",
    "\n",
    "with $\\tilde{\\mathbf{z}} := g_{\\boldsymbol{\\phi}}\\left(\\boldsymbol{\\epsilon},\\mathbf{x} \\right), \\epsilon \\sim p(\\epsilon) \\text{ and } f_{\\theta, \\phi}(\\mathbf{z}, \\mathbf{x}) := \\log \\frac{p_\\theta(\\mathbf{x}, \\mathbf{z})}{q_\\phi(\\mathbf{z}|\\mathbf{x})}$ .\n",
    "\n",
    "\n",
    "#### Choice of Reparameterization\n",
    "\n",
    "A common choice of parameterization is to choose $p(\\epsilon) = \\mathcal{N} (0, I)$ and parameterize a mean vector and a diagonal covariance matrix using neural networks $\\{\\mu_\\phi, \\sigma_\\phi\\}$:\n",
    "\n",
    "$$\\mathbf{z} = \\mu_\\phi(\\mathbf{x}) + \\sigma_\\phi(\\mathbf{x})  \\odot \\epsilon \\ \\text{   with   }  \\epsilon \\sim \\mathcal{N} (0, I) \\ . $$\n",
    "\n",
    "### Why a VAE learns a good approximate posterior $q_\\phi(\\mathbf{z} | \\mathbf{x}) \\approx p_\\theta(\\mathbf{z} | \\mathbf{x})$\n",
    "\n",
    "We have seen how to estimate the parameter $\\phi$ thanks to the reparameterization. Maximizing the ELBO will\n",
    "maximize its upper bound $\\log p_\\theta(\\mathbf{x})$. Yet, maximizing $\\log p_\\theta(\\mathbf{x})$ does not guarantee a good approximation\n",
    "$q_\\phi(\\mathbf{z} | \\mathbf{x}) \\approx p_\\theta(\\mathbf{z} | \\mathbf{x})$, and a poor approximation leads to a low-accuracy estimate of $\\log p_\\theta(\\mathbf{x})$.\n",
    "\n",
    "At the end of the note book, we show that the following identity holds:\n",
    "\n",
    "$$\\log p_\\theta(\\mathbf{x}) = \\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x}) | p_\\theta(\\mathbf{z}| \\mathbf{x})) + \\mathcal{L}(\\mathbf{x}) \\geq \\mathcal{L}(\\mathbf{x})$$\n",
    "\n",
    "Hence maximizing the ELBO also guarantees to push the approximate posterior $q_\\phi(\\mathbf{z}| \\mathbf{x})$ to be similar to the true posterior  $p_\\theta(\\mathbf{z}| \\mathbf{x})$ because $\\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x}) | p_\\theta(\\mathbf{z}| \\mathbf{x}))$ is minimized as $\\mathcal{L}$ is maximized.\n",
    "\n",
    "## 4. Interpreting VAEs as Autoencoders\n",
    "\n",
    "Similarly to the Autoencoder introduced in the previous notebook, the Variational Autoencoder admits an *encoder* model $g_\\phi(\\mathbf{x}, \\epsilon)$ parameterizing the posterior $q_\\phi(\\mathbf{z} | \\mathbf{x})$ and a *decoder* $h_\\theta(\\mathbf{z})$ parameterizing the observation model $p_\\theta(\\mathbf{x} | \\mathbf{z})$. Hence, a VAE is much similar to a classic autoencoder (as introduced in the notebook 7.1): instead of computing $\\mathbf{z} = h_\\phi(\\mathbf{x})$ (deterministic: autoencoder), a VAE exploits a stochastic model $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$ (see the top figure). \n",
    "\n",
    "When using the reparameterization-trick, this is equivalent to adding noise to the stochastic representation $\\mathbf{z} = \\mu_\\phi(\\mathbf{x}) + \\sigma_\\phi(\\mathbf{x})  \\odot \\epsilon$ with  $\\epsilon \\sim \\mathcal{N} (0, I)$.\n",
    "\n",
    "The ELBO introduces a tradeoff between reconstruction quality and the regularizer $\\mathcal{D}_{\\operatorname{KL}}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x})\\ |\\ p(\\mathbf{z})\\right)$. It is possible to target different regularization strenghts using the following modified ELBO loss ([$\\beta-VAE$](https://openreview.net/references/pdf?id=Sy2fzU9gl)):\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{\\beta}(\\mathbf{x}) := \n",
    "\\overbrace{\n",
    "\\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[ \\log p_\\theta(\\mathbf{x} | \\mathbf{z})\\right]\n",
    "}^{\\text{(a) Reconstruction Error}}\n",
    "- \n",
    "\\beta\n",
    "\\cdot\n",
    "\\overbrace{\n",
    "\\mathcal{D}_{\\operatorname{KL}}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x})\\ |\\ p(\\mathbf{z})\\right)\n",
    "}^{\\text{(b) Regularization}}\n",
    "$$\n",
    "\n",
    "\n",
    "## 5. Modelling Choices: How to design a VAE\n",
    "\n",
    "\n",
    "### Prior $p_{\\theta}(\\mathbf{z})$\n",
    "\n",
    "The prior distribution structures the latent space. Althougt it is common to choose a simple *variaitonal family* (Diagonal Gaussian or Categorical), more complex prior distributions can be used including complex factorizations (e.g. autoregressive: $p(\\mathbf{z}) = p_\\theta(\\mathbf{z_1}) \\prod_{l=1}^{L-1} p_{\\theta}(\\mathbf{z}_{l+1} | \\mathbf{z}_l) $ ). By default, the prior is commonly chosen to be a simple Gaussian distribution: $$p(\\mathbf{z}) := \\mathcal{N}(0, I)$$\n",
    "\n",
    "### Posterior $q_\\phi(\\mathbf{z}|\\mathbf{x})$\n",
    "\n",
    "The posterior is chosen to be of the same variational family as the prior. When using the reparameterization trick, the posterior must admit a reparameterization. A common choice fitting the Gaussian prior is a Diagonal Gaussian distribution: $$q_\\phi(\\mathbf{z} | \\mathbf{x}) := \\mathcal{N}( \\mathbf{z}\\ |\\ \\mu_\\phi(\\mathbf{x}) , \\sigma_\\phi(\\mathbf{x}) I )$$\n",
    "\n",
    "\n",
    "### Observation Model $p_\\theta(\\mathbf{x} | \\mathbf{z})$\n",
    "\n",
    "The choice of the observation model depends on the nature of the features, so for binary pixel values an appropiate choice of reconstruction distribution is the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution), $$p_\\theta(\\mathbf{x}|\\mathbf{z}) = \\prod_i \\mathcal{B}(x_i | g_\\theta(\\mathbf{z})) = \\prod_i g_\\theta(\\mathbf{z})_i^{x_i} \\cdot (1-g_\\theta(\\mathbf{z})_i)^{1-x_i}$$ where $x_1, \\dots, x_D \\in \\{0,1\\}^{D}$ are the pixel values of the image $\\mathbf{x}$. $g_\\theta$ is the *decoder* of the VAE. $g_\\theta(z)_i$ is the probability of generating a 0 (black) or 1 (white) for the $i$-th pixel value. This is equivalent to modelling 784 imbalanced coin-tossing processes. This is only possible because we assume the pixel intensities to be i.i.d. (Independent and Identically Distributed), which means $p(\\mathbf{x}) = \\prod_i p(x_i)$ , so no direct correlations between them needs to modelled, even though we still achieve an indirect conditional correlation through the latent variables, $\\mathbf{z}$.\n",
    "\n",
    "\n",
    "## 6. Evaluating a Variational Autoencoder\n",
    "\n",
    "### Assessing the Quality of the Samples\n",
    "\n",
    "The Variational Autoencoder defines a generative process $\\mathbf{z} \\sim p_{\\theta}(\\mathbf{z}), \\  \\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} | \\mathbf{z})$. A *good* VAE should explain well the data $\\mathbf{x}$ and samples $\\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} |\\mathbf{z}), \\mathbf{z} \\sim p_{\\theta}(\\mathbf{z})$ should be representive of the dataset.\n",
    "\n",
    "### Estimating the Likelihood\n",
    "\n",
    "A VAE defines a probabilistic model $p_\\theta(\\mathbf{x} | \\mathbf{z}) p(\\mathbf{z})$ and we are interested in maximizing the ability of the model to explain the dataset $\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1, \\dots, N}$, hence we aim at obtaining the maximum probability $\\log p_\\theta(\\mathcal{D}) = \\sum_{i=1}^N \\log p_\\theta(\\mathbf{x}_i) =  \\sum_{i=1}^N \\log \\int_\\mathbf{z} p_\\theta(\\mathbf{x}_i, \\mathbf{z}) d\\mathbf{z} $. However, as discussed previously, the log-likelihood is intractable (marginalization over $\\mathbf{z}$), hence we rely on the Evidence Lower Bound (ELBO) as a proxy, or a tighter bound such as the importance weighted bound (see at the end of the notebook). \n",
    "\n",
    "**NB** It is common practice to report the average marginal log likelihood $\\log p_\\theta(\\mathcal{D}) / N$ and not $\\log p_\\theta(\\mathcal{D})$ directly:\n",
    "\n",
    "$$\\frac{1}{N} \\log p_\\theta(\\mathcal{D}) = \\frac{1}{N} \\sum_i \\log p_\\theta(\\mathbf{x}_i) \\geq \\frac{1}{N} \\sum_i \\operatorname{ELBO}(\\mathbf{x}_i) \\ . $$\n",
    "\n",
    "### Evaluation on Downstream Tasks\n",
    "\n",
    "As explained in the previous notebook, there is an interest in learning *compressed* representations $\\mathbf{z}$ of $\\mathbf{x}$ with the intent of solving downstream tasks such as classification. In this scenario, it is important to evaluate the VAE on the final task. For instance, learning a classifier using $\\mathbf{z}$ as features: $p(y | \\mathbf{z})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice: Building and Training VAEs\n",
    "\n",
    "## Probabilistic Building Blocks\n",
    "\n",
    "First, we will implement modules representing probability distributions, which are essential in probabilistic machine learning. Here, we loosely follow the implementation from the `torch.distributions` package which provides modules for most of the commonly used distributions. \n",
    "\n",
    "### 1. Gaussian Distribution\n",
    "\n",
    "The Gaussian distribution is parameterized by two parameters:\n",
    "* the location parameter $\\mu$\n",
    "* the scale parameter $\\sigma \\geq 0$.\n",
    "\n",
    "\n",
    "**Exercise 1**: Implement a Gaussian distribution from the parameters $\\mu$ and $\\log \\sigma$ using the following code. The method `rsample()` should be compatible with the reparameterization trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        raise NotImplementedError # <- your code\n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        raise NotImplementedError # <- your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test your implementation\n",
    "\n",
    "def test_normal_distribution():\n",
    "    \"\"\"a few safety checks for your implementation\"\"\"\n",
    "    N = 1000000\n",
    "    ones = torch.ones(torch.Size((N,)))\n",
    "    mu = 1.224 * ones\n",
    "    sigma = 0.689 * ones\n",
    "    dist = ReparameterizedDiagonalGaussian(mu, sigma.log())\n",
    "    z = dist.sample()\n",
    "    \n",
    "    # Expected value E[N(0, 1)] = 0\n",
    "    expected_z = z.mean()\n",
    "    diff = (expected_z - mu.mean())**2\n",
    "    assert diff < 1e-3, f\"diff = {diff}, expected_z = {expected_z}\"\n",
    "    \n",
    "    # Variance E[z**2 - E[z]**2]\n",
    "    var_z = (z**2 - expected_z**2).mean()\n",
    "    diff = (var_z - sigma.pow(2).mean())**2\n",
    "    assert diff < 1e-3, f\"diff = {diff}, var_z = {var_z}\"\n",
    "    \n",
    "    # log p(z)\n",
    "    from torch.distributions import Normal\n",
    "    base = Normal(loc=mu, scale=sigma)\n",
    "    diff = ((base.log_prob(z) - dist.log_prob(z))**2).mean()\n",
    "    assert diff < 1e-3, f\"diff = {diff}\"\n",
    "\n",
    "test_normal_distribution()   \n",
    "\n",
    "n_samples = 10000\n",
    "mu = torch.tensor([[0, 1]])\n",
    "sigma = torch.tensor([[0.5 , 3]])\n",
    "ones = torch.ones((1000,2))\n",
    "p = ReparameterizedDiagonalGaussian(mu=mu*ones, log_sigma=(sigma*ones).log())\n",
    "samples = p.sample()\n",
    "data = pd.DataFrame({\"x\": samples[:, 0], \"y\": samples[:, 1]})\n",
    "g = sns.jointplot(\n",
    "    data=data,\n",
    "    x=\"x\",y=\"y\",\n",
    "    kind=\"hex\",\n",
    "    ratio=10\n",
    ")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(r\"$\\mathcal{N}(\\mathbf{y} \\mid \\mu, \\sigma)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### 2. Bernoulli Distribution\n",
    "\n",
    "The Bernoulli distribution is a good fit when modelling binary outcomes (e.g. coin flipping). Given a binary random variable $X$ with outcomes $y \\in \\{0, 1\\}$, the probability density of the Bernoulli model with a parameter $\\theta$ is defined as\n",
    "$$\\mathcal{B}( y \\mid \\theta) = \\theta^{y} (1-\\theta)^{1-y},\\quad \\theta \\in [0,1]$$\n",
    "\n",
    "**Exercise 1**: Import the `Bernoulli` from the [torch.distributions](https://pytorch.org/docs/stable/distributions.html) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <- your code\n",
    "\n",
    "p = Bernoulli(logits=torch.zeros((1000,)))\n",
    "plt.figure(figsize=(12, 3))\n",
    "sns.distplot(p.sample())\n",
    "plt.title(r\"$\\mathcal{B}(\\mathbf{y} \\mid \\mathbf{\\theta})$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset: MNIST\n",
    "\n",
    "First let us load the MNIST dataset and plot a few examples. We only load a limited amount of classes, controlled through the `classes` variable, to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "# Flatten the images into a vector\n",
    "flatten = lambda x: ToTensor()(x).view(28**2)\n",
    "\n",
    "# Define the train and test sets\n",
    "dset_train = MNIST(\"./\", train=True,  transform=flatten, download=True)\n",
    "dset_test  = MNIST(\"./\", train=False, transform=flatten)\n",
    "\n",
    "# The digit classes to use\n",
    "classes = [3, 7]\n",
    "\n",
    "def stratified_sampler(labels):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "eval_batch_size = 100\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size,\n",
    "                          sampler=stratified_sampler(dset_train.train_labels))\n",
    "test_loader  = DataLoader(dset_test, batch_size=eval_batch_size, \n",
    "                          sampler=stratified_sampler(dset_test.test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a few MNIST examples\n",
    "f, axarr = plt.subplots(4, 16, figsize=(16, 4))\n",
    "\n",
    "# Load a batch of images into memory\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(images[i].view(28, 28), cmap=\"binary_r\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.suptitle('MNIST handwritten digits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the model\n",
    "When defining the model the latent layer must act as a bottleneck of information, so that we ensure that we find a strong internal representation. We initialize the VAE with 1 hidden layer in the encoder and decoder using relu units as non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    \"\"\"A Variational Autoencoder with\n",
    "    * a Bernoulli observation model `p_\\theta(x | z) = B(x | g_\\theta(z))`\n",
    "    * a Gaussian prior `p(z) = N(z | 0, I)`\n",
    "    * a Gaussian posterior `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        \n",
    "\n",
    "        # Inference Network\n",
    "        # Encode the observation `x` into the parameters of the posterior distribution\n",
    "        # `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x)), \\mu(x),\\log\\sigma(x) = h_\\phi(x)`\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.observation_features, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            # A Gaussian is fully characterised by its mean \\mu and variance \\sigma**2\n",
    "            nn.Linear(in_features=128, out_features=2*latent_features) # <- note the 2*latent_features\n",
    "        )\n",
    "        \n",
    "        # Generative Model\n",
    "        # Decode the latent sample `z` into the parameters of the observation model\n",
    "        # `p_\\theta(x | z) = \\prod_i B(x_i | g_\\theta(x))`\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_features, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=self.observation_features)\n",
    "        )\n",
    "        \n",
    "        # define the parameters of the prior, chosen as p(z) = N(0, I)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "    def posterior(self, x:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\"\"\"\n",
    "        \n",
    "        # compute the parameters of the posterior\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        \n",
    "        # return a distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def prior(self, batch_size:int=1)-> Distribution:\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "        \n",
    "        # return the distribution `p(z)`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def observation_model(self, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "        px_logits = self.decoder(z)\n",
    "        px_logits = px_logits.view(-1, *self.input_shape) # reshape the output\n",
    "        return Bernoulli(logits=px_logits, validate_args=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x) -> Dict[str, Any]:\n",
    "        \"\"\"compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)\"\"\"\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.posterior(x)\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        \n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}\n",
    "    \n",
    "    \n",
    "    def sample_from_prior(self, batch_size:int=100):\n",
    "        \"\"\"sample z~p(z) and return p(x|z)\"\"\"\n",
    "        \n",
    "        # degine the prior p(z)\n",
    "        pz = self.prior(batch_size=batch_size)\n",
    "        \n",
    "        # sample the prior \n",
    "        z = pz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'z': z}\n",
    "\n",
    "\n",
    "latent_features = 2\n",
    "vae = VariationalAutoencoder(images[0].shape, latent_features)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implement a module for Variational Inference\n",
    "\n",
    "**Exercise 1**: implement `elbo` ($\\mathcal{L}$) and `beta_elbo` ($\\mathcal{L}^\\beta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reduce(x:Tensor) -> Tensor:\n",
    "    \"\"\"for each datapoint: sum over all dimensions\"\"\"\n",
    "    return x.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "class VariationalInference(nn.Module):\n",
    "    def __init__(self, beta:float=1.):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, model:nn.Module, x:Tensor) -> Tuple[Tensor, Dict]:\n",
    "        \n",
    "        # forward pass through the model\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # unpack outputs\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        # evaluate log probabilities\n",
    "        log_px = reduce(px.log_prob(x))\n",
    "        log_pz = reduce(pz.log_prob(z))\n",
    "        log_qz = reduce(qz.log_prob(z))\n",
    "        \n",
    "        # compute the ELBO with and without the beta parameter: \n",
    "        # `L^\\beta = E_q [ log p(x|z) ] - \\beta * D_KL(q(z|x) | p(z))`\n",
    "        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = # <- your code here\n",
    "        beta_elbo = # <- your code here\n",
    "        \n",
    "        # loss\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # prepare the output\n",
    "        with torch.no_grad():\n",
    "            diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}\n",
    "            \n",
    "        return loss, diagnostics, outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vi = VariationalInference(beta=1.0)\n",
    "loss, diagnostics, outputs = vi(vae, images)\n",
    "print(f\"{'loss':6} | mean = {loss:10.3f}, shape: {list(loss.shape)}\")\n",
    "for key, tensor in diagnostics.items():\n",
    "    print(f\"{key:6} | mean = {tensor.mean():10.3f}, shape: {list(tensor.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "### Initialize the model, evaluator and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# VAE\n",
    "latent_features = 2\n",
    "vae = VariationalAutoencoder(images[0].shape, latent_features)\n",
    "\n",
    "# Evaluator: Variational Inference\n",
    "beta = 1\n",
    "vi = VariationalInference(beta=beta)\n",
    "\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "**plotting guide**:\n",
    "\n",
    "* 1st row: Reproducing the figure from the begining of the Notebook.\n",
    "    * (Left) Data. \n",
    "    * (Middle) Latent space: the large gray disk reprensents the prior (radius = $2\\sigma$), each point represents a latent sample $\\mathbf{z}$. The smaller ellipses represent the distributions $q_\\phi(\\mathbf{z} | \\mathbf{x})$  (radius = $2\\sigma$). When using $\\geq 2$ latent features, dimensionality reduction is applied using t-SNE and only samples $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$ are displayed. \n",
    "    * (Right) samples from $p_\\theta(\\mathbf{x} | \\mathbf{z})$.\n",
    "\n",
    "* 2nd row: Training curves\n",
    "\n",
    "* 2rd row: Latent samples. \n",
    "    * (Left) Prior samples $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim p(\\mathbf{z})$ \n",
    "    * (Middle) Latent Interpolations. For each row: $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | t \\cdot \\mathbf{z}_1 + (1-t) \\cdot \\mathbf{z}_2), \\mathbf{z}_1, \\mathbf{z}_2 \\sim p(\\mathbf{z}), t=0 \\dots 1$. \n",
    "    * (Right): Sampling $\\mathbf{z}$ from a grid [-3:3, -3:3] $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim \\operatorname{grid}(-3:3, -3:3)$ (only available for 2d latent space).\n",
    "\n",
    "**NOTE** this will take a while on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# move the model to the device\n",
    "vae = vae.to(device)\n",
    "\n",
    "# training..\n",
    "while epoch < num_epochs:\n",
    "    epoch+= 1\n",
    "    training_epoch_data = defaultdict(list)\n",
    "    vae.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBO\n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gather data for the current bach\n",
    "        for k, v in diagnostics.items():\n",
    "            training_epoch_data[k] += [v.mean().item()]\n",
    "            \n",
    "\n",
    "    # gather data for the full epoch\n",
    "    for k, v in training_epoch_data.items():\n",
    "        training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "    # Evaluate on a single batch, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        \n",
    "        # Just load a single batch from the test loader\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBO\n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        \n",
    "        # gather data for the validation step\n",
    "        for k, v in diagnostics.items():\n",
    "            validation_data[k] += [v.mean().item()]\n",
    "    \n",
    "    # Reproduce the figure from the begining of the notebook, plot the training curves and show latent samples\n",
    "    make_vae_plots(vae, x, y, outputs, training_data, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the VAE\n",
    "\n",
    "## Mandatory Exercises\n",
    "\n",
    "### Exercise 1.\n",
    "\n",
    "1. Implement the class `ReparameterizedDiagonalGaussian` (`log_prob()` and `rsample()`).\n",
    "2. Import the class `Bernoulli`\n",
    "3. Implement the class `VariationalInference` (computation of the `elbo` and `beta_elbo`).\n",
    "\n",
    "### Exercise 2.\n",
    "\n",
    "**Trainnig and Evaluating a VAE model**\n",
    "\n",
    "1. Why do we use the reparameterization trick?\n",
    "2. What available metric can you use to estimate the marginal likelihood ($p_\\theta(\\mathbf{x})$) ?\n",
    "3. In the above plots, we display numerous model samples. If you had to pick one plot, which one would you pick to evaluate the quality of a VAE (i.e. using posterior samples $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$ or prior samples $\\mathbf{z} \\sim p(\\mathbf{z})$) ? Why?.\n",
    "4. How could you exploit the VAE model for classification?\n",
    "\n",
    "**Answers**:\n",
    "\n",
    "`[...]`\n",
    "\n",
    "### Exercise 3.\n",
    "\n",
    "**Experiment with the VAE model.**\n",
    "\n",
    "1. Experiment with the number of layers and activation functions in order to improve the reconstructions and latent representation. What solution did you find the best and why?\n",
    "2. Try to increase the number of digit classes in the training set and analyze the learning curves, latent space and reconstructions. For which classes and why does the VAE fail in reconstructing?  *HINT: Try the combination: `classes=[0, 1, 4, 9]`, to see how well VAE can separate these digits in the latent representation and reconstructions.*\n",
    "3. Increase the number of units in the latent layer. Does it increase the models representational power and how can you see and explain this? How does this affect the quality of the reconstructions?\n",
    "\n",
    "**Answers**:\n",
    "\n",
    "`[...]`\n",
    "\n",
    "### Exercise 4. \n",
    "\n",
    "**Analyze the purpose of the KL-term and the $\\beta$ parameter.**\n",
    "\n",
    "1. How does the KL-term, $\\mathcal{D}_{\\operatorname{KL}}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x})\\ |\\ p(\\mathbf{z})\\right)$, work as a regulariser on the distributions over latent variables? *HINT*: When maximising the ELBO, the probability-distance measure is minimised $\\operatorname{KL} \\rightarrow 0$ so that $q(z|x) \\rightarrow p(z) = \\mathcal{N}(z|0,I)$ for all examples, x. At $\\operatorname{KL} = 0$ variations in x stops having an affect on the latent distribution and latent units are all described by the same distribution, $\\mathcal{N}(z|0,I)$, so they produce a noisy output without signal (i.e. $\\mathbf{z}=\\epsilon \\sim \\mathcal{N}(0,I)$) to the decoder.\n",
    "2. Try removing the KL-term (using the $\\beta$ parameter) and analyze what happens during training, in the learning curves, latent representation and reconstructions compared to before removing it.\n",
    "3. What does the loss reduces to? Explain how this can affect a VAE. *HINT*: Compare loss function for AE and VAE, and remember that we can use the pixel-wise binary crossentropy error as the loss in the AEs and for the reconstruction error, $\\log p_\\theta(\\mathbf{x}|\\mathbf{z}) = \\log \\mathcal{B}(\\mathbf{x} | g_\\theta(z))$, in VAEs.\n",
    "4. Experiment with different $\\beta$ values (e.g. [0.1, 10, 50]) and explain how this affects the reconstruction quality and the latent representations. *HINT* what is the tradeoff between reconstruction error ($\\log p_\\theta(\\mathbf{x} | \\mathbf{z})$) and the KL term?\n",
    "\n",
    "**Answers**:\n",
    "\n",
    "`[...]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optional exercises\n",
    "\n",
    "- OPT: Use the original paper http://arxiv.org/pdf/1312.6114v10.pdf or [this blog](http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/) to explain what the reparameterization trick does.\n",
    "- OPT: Look through https://arxiv.org/abs/1611.00712 or https://arxiv.org/abs/1611.01144 and explain how one could instead introduce a categorical latent variable for $z$.\n",
    "- OPT: Implement the Gumbel softmax trick thereby letting $z$ take a categorical distribution.\n",
    "- OPT: The VAE is a probablistic model. We could model $p(x,z,y)$ where $y$ is the label information. Explain how this model could handle semi-supervised learning? You can look through the papers https://arxiv.org/pdf/1406.5298.pdf or  https://arxiv.org/pdf/1602.05473v4.pdf or again the two papers on Gumbel softmax.\n",
    "\n",
    "**Answers**:\n",
    "\n",
    "`[...]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits \n",
    "\n",
    "- Original [Theano/Lasagne tutorial](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016/blob/master/lab1/lab1_FFN.ipynb) by \n",
    "Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee)),\n",
    "Søren Kaae Sønderby ([skaae](https://github.com/skaae)), and \n",
    "Casper Sønderby ([casperkaae](https://github.com/casperkaae)). \n",
    "- Converted to TensorFlow and updated by Maximillian F. Vording ([maximillian91](https://github.com/maximillian91)).\n",
    "- Converted to PyTorch and updated by Jesper Wohlert ([wohlert](https://github.com/wohlert)).\n",
    "- Major update in 2020: focus on the probabilistic interpretation, use of `torch.distributions` and improved visualizations by Valentin Lievin ([vlievin](http://vlievin.github.io))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Supplementary Material\n",
    "\n",
    "## Why a VAE learns a good approximate posterior $q_\\phi(\\mathbf{z} | \\mathbf{x}) \\approx p_\\theta(\\mathbf{z} | \\mathbf{x})$\n",
    "\n",
    "In order to compare the two distributions, let us focus on their KL-divergence (**important**: the divergence is expressed w.r.t $p_\\theta(\\mathbf{z}|\\mathbf{x})$ and not $p(\\mathbf{z})$, this is not the KL-divergence studied in the experiments):\n",
    "\n",
    "$$\\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x}) || p_\\theta(\\mathbf{z} | \\mathbf{x})) = \\int_z q_\\phi(\\mathbf{z} | \\mathbf{x}) \\log \\frac{q_\\phi(\\mathbf{z} | \\mathbf{x}) }{p_\\theta(\\mathbf{z} | \\mathbf{x})}dz = \\mathbb{E}_{q_\\phi(\\mathbf{z} | \\mathbf{x})} \\left[\\log \\frac{q_\\phi(\\mathbf{z} | \\mathbf{x}) }{p_\\theta(\\mathbf{z} | \\mathbf{x})}\\right]$$\n",
    "\n",
    "which is a non-negative distance measure between distributions, so by minimising it wrt. to the parameters in $q_\\phi(\\mathbf{z} | \\mathbf{x}) $, the distribution moves close to our unknown $p_\\theta(\\mathbf{z} | \\mathbf{x})$. But as $p_\\theta(\\mathbf{z} | \\mathbf{x})$ is unknown and would include some rather intractable integrals over neural networks, we can instead get rid of it by expressing it through Bayes rule $p(z|x) = p(x|z)p(z)/p(x)$ and thereby decompose the KL-divergence into our log-likelihood and lower bound:\n",
    "\n",
    "$$ \\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x})  || p_\\theta(\\mathbf{z} | \\mathbf{x})) \n",
    "= \\int_\\mathbf{z} q_\\phi(\\mathbf{z} | \\mathbf{x}) \\log \\frac{q_\\phi(\\mathbf{z} | \\mathbf{x}) p_\\theta(\\mathbf{x})}{p_\\theta(\\mathbf{x} | \\mathbf{z})\n",
    "p(z)}d\\mathbf{z}\n",
    "= \\int_\\mathbf{z} q_\\phi(\\mathbf{z} | \\mathbf{x}) \\log \\frac{q_\\phi(\\mathbf{z} | \\mathbf{x}) }{p_\\theta(\\mathbf{x} | \\mathbf{z})p_\\theta(\\mathbf{x} | \\mathbf{z})(\\mathbf{z})}d\\mathbf{z} + \\log p_\\theta(\\mathbf{x})$$ \n",
    "\n",
    "by seeing that the likelihood, $p_\\theta(\\mathbf{x})$, is independent of $\\mathbf{z}$ and pull it out of the integral. We can flip the sign and fraction in the integral term to recognise it as the negative lower bound\n",
    "\n",
    "$$\\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x})  || p_\\theta(\\mathbf{z} | \\mathbf{x})) = - \\int_z q_\\phi(\\mathbf{z} | \\mathbf{x}) \\log \\frac{p_\\theta(\\mathbf{x} | \\mathbf{z})p(\\mathbf{z})}{q_\\phi(\\mathbf{z} | \\mathbf{x}) }dz + \\log p_\\theta(\\mathbf{x}) =  -\\mathcal{L}(x) + \\log p_\\theta(\\mathbf{x})$$\n",
    "\n",
    "We then find the log-likelihood to consist of the two terms and hold the inequality\n",
    "\n",
    "$$\\log p_\\theta(\\mathbf{x}) =  \\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x})  || p_\\theta(\\mathbf{z} | \\mathbf{x})) + \\mathcal{L}(\\mathbf{x}) \\geq \\mathcal{L}(\\mathbf{x})$$\n",
    "\n",
    "where the KL-divergence is non-zero and the log-likelihood is $\\log p_\\theta(\\mathbf{x}) \\leq 0$. This means that maximising the lower bound from the negative domain towards $0$ will also maximise the log-likelihood, while pushing down the KL-divergence until $q_\\phi(\\mathbf{z} | \\mathbf{x}) $ cannot move closer to natures true distribution, $p_\\theta(\\mathbf{z} | \\mathbf{x})$. So how close the lower bound can get to the log-likelihood is dependent on the flexibility of the distribution we choose for $q_\\phi(\\mathbf{z} | \\mathbf{x}) $. \n",
    "\n",
    "\n",
    "\n",
    "## Importance Sampling in VAEs\n",
    "\n",
    "In VAEs, the true posterior distribution $p_\\theta(\\mathbf{z} | \\mathbf{x})$ is unknown. Instead we use an approximate posterior $q_\\theta(\\mathbf{z} | \\mathbf{x})$. $q$ is tractable and one can sample from it. This is an instance of importance-sampling: evaluating a quantity $\\mathbb{E}_{p(\\mathbf{z})} \\left[  f(\\mathbf{z})\\right]$ given samples from another distribtion $q$.\n",
    "\n",
    "### 1. Illustration\n",
    "\n",
    "Let us consider a small example to illustrate importance-sampling. In this example we define a distribution $p(\\mathbf{z})$ from which we (in practice) cannot sample and define a distribution $q(\\mathbf{z})$ from which we can sample. \n",
    "\n",
    "Then we can estimate $\\mathbb{E}_{p(\\mathbf{z})} \\left[  f(\\mathbf{z})\\right]$ using samples from $q$:\n",
    "\n",
    "$$\\mathbb{E}_{p(\\mathbf{z})} \\left[  f(\\mathbf{z})\\right] = \\mathbb{E}_{q(\\mathbf{z})} \\left[ w(\\mathbf{z}) f(\\mathbf{z})\\right], \\quad w(\\mathbf{z}) := \\frac{p(\\mathbf{z})}{q(\\mathbf{z})}$$\n",
    "\n",
    "In this example, we use $f(\\mathbf{z}) = \\mathbf{z}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "cuda = torch.cuda.is_available()\n",
    "    \n",
    "n_samples = 10000\n",
    "c1 = sns.color_palette()[0]\n",
    "c2 = sns.color_palette()[1]\n",
    "\n",
    "# define p(z) and q(z)\n",
    "p = Normal(loc=5 * torch.ones((1,)), scale=torch.ones((1,))) \n",
    "q = Normal(loc=torch.ones((1,)), scale=3*torch.ones((1,)))\n",
    "\n",
    "# sample z ~ q(z)\n",
    "q_samples = q.sample(sample_shape=torch.Size([n_samples]))\n",
    "\n",
    "# compute the densities p(z) and q(z)\n",
    "p_prob = p.log_prob(q_samples).exp()\n",
    "q_prob = q.log_prob(q_samples).exp()\n",
    "\n",
    "# define the importance-weights: w(z) = p(z) / q(z)\n",
    "w = p_prob / (q_prob + 1e-12)\n",
    "\n",
    "# compute the importance-weighted estimate \\hat{\\mu} = E_q[ w(z) f(z)] where f(z) = z\n",
    "estimate = (w * q_samples).mean()\n",
    "\n",
    "# compute the ground true\n",
    "p_samples = p.sample(sample_shape=torch.Size([n_samples]))\n",
    "empirical_mean = p_samples.mean()\n",
    "\n",
    "# display the results\n",
    "print(f\">> Empirical mean = {empirical_mean:.3f}, estimate = {estimate:.3f}\")\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.distplot(p_samples, label=\"$p(z)$\", hist_kws={'alpha':0.2}, color=c1)\n",
    "sns.distplot(q_samples, label=\"$q(z)$\",hist_kws={'alpha':0.2}, color=c2)\n",
    "plt.axvline(empirical_mean, color=c1,linestyle=\"-\",label= \"Empirical Mean\")\n",
    "plt.axvline(estimate, color=c2,linestyle=\"-\", label= \"Importance-Weighted Estimate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Application: Accurate Estimate of $\\log p_\\theta(\\mathbf{x})$ using Importance Sampling\n",
    "\n",
    "The ELBO is a lower bound to the marginal log likelihood, however it is not guaranteed to be accurate. [Importance-sampling can be leveraged in VAEs](https://arxiv.org/abs/1509.00519) to provide a more accurate estimate of the marginal log-likelihood $\\log p_\\theta(\\mathbf{x})$ using multiple samples from $q_\\phi(\\mathbf{z}_1,\\dots,\\mathbf{z}_K | \\mathbf{x})$. With $K+1$ samples $q_\\phi(\\mathbf{z} | \\mathbf{x})$, the following inequality holds:\n",
    "\n",
    "$$\\log p_\\theta(\\mathbf{x}) \\geq \\mathcal{L}_{K+1}(\\mathcal{x}) \\geq \\mathcal{L}_K(\\mathcal{x}) \\geq \\mathcal{L}(\\mathcal{x})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mathcal{L}_{K}(\\mathcal{x}) := \\mathbb{E}_{q_\\phi(\\mathbf{z}_1,\\dots,\\mathbf{z}_K | \\mathbf{x})} \\left[ \n",
    "\\log \\frac{1}{K} \\sum_{k=1}^K \\frac{p_\\theta(\\mathbf{x}, \\mathbf{z}_k)}{q_\\phi(\\mathbf{z}_k | \\mathbf{x})} \n",
    "\\right]$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02456",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
